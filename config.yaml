data:
  magphys:
    path: "data/input/magphys.csv"
    features: ['Z', 'FUV_flux', 'NUV_flux', 'u_flux', 'g_flux', 'r_flux', 'i_flux', 'z_flux','X_flux', 'Y_flux', 'J_flux', 'H_flux', 'K_flux', 'W1_flux', 'W2_flux', 'W3_flux', 'W4_flux', 'P100_flux', 'P160_flux', 'S250_flux', 'S350_flux', 'S500_flux']
    targets:
      SFR_0_1Gyr_percentile50:
        plotting:
          display_name: "SFR"
          display_unit: r"$\log(\mathrm{SFR})$ $(M_{\odot}\,/\,\mathrm{yr})$"
        dl:
          layers: [128, 48, 112, 32, 48]
          activation: 'relu'    # Choose: relu, elu, tanh
          regularizer: 'l1'  # Choose: l1, l2, l1_l2, None
          optimizer: 'adam'    # Choose: adam, sgd, rmsprop
          learning_rate: 0.0006593261627622872
          batch_size: 128
          epochs: 600
        wdnn:
          layers: [64, 64, 80, 64]
          activation: 'relu'    # Choose: relu, elu, tanh
          regularizer: 'l1'  # Choose: l1, l2, l1
          optimizer: 'adam'    # Choose: adam, sgd, rmsprop
          learning_rate: 0.001014754247313394
          batch_size: 192
          epochs: 900
        xgboost:
          eta: 0.051443613360991416
          n_estimators: 900
          max_depth: 5
          reg_lambda: 0.17120657819970742
          reg_alpha: 0.5787738773710711
          colsample_bytree: 0.5787738773710711
        catboost:
          iterations: 2000
          depth: 6
          learning_rate: 0.07351719163027079
      mass_stellar_percentile50:
        plotting:
          display_name: "SM"
          display_unit: r"$\log(M_{*}[M_{\odot}])$"
        dl:
          layers: [96, 96, 112, 48]
          activation: 'relu'
          regularizer: None  # Choose: l1, l2, l1_l2, None
          optimizer: 'adam'
          learning_rate: 0.001205671828009621
          batch_size: 64
          epochs: 400
        wdnn:
          layers: [128, 48, 112, 64]
          activation: 'relu'    # Choose: relu, elu, tanh
          regularizer: None  # Choose: l1, l2, l1_l2, None
          optimizer: 'adam'    # Choose: adam, sgd, rms
          learning_rate: 0.0015478594550778974
          batch_size: 64
          epochs: 500
        xgboost:
          eta: 0.07921249558600041
          n_estimators: 1000
          max_depth: 5
          reg_lambda: 0.613792185383374
          reg_alpha: 0.25908622248033286
          colsample_bytree: 0.5058734778609052
        catboost:
          iterations: 1900
          depth: 5
          learning_rate: 0.07435761347070234
  mpa-jhu:
    path: "data/input/mpajhu.csv"
    features: ['r', 'u-g', 'g-r', 'r-i', 'i-z', 'z-w1', 'w1-w2', 'w2-w3']
    targets:
      SFR_TOT_P50:
        plotting:
          display_name: "SFR"
          display_unit: r"$\log(\mathrm{SFR})$ $(M_{\odot}\,/\,\mathrm{yr})$"
        dl:
          layers: [96, 128, 96, 80, 48]
          activation: 'elu'    # Choose: relu, elu, tanh
          regularizer: None  # Choose: l1, l2, l1_l2, None
          optimizer: 'rmsprop'    # Choose: adam, sgd, rmsprop
          learning_rate: 0.00011288326498993341
          batch_size: 32
          epochs: 900 
        wdnn:
          layers: [112, 96, 32, 96]
          activation: 'relu'    # Choose: relu, elu, tanh
          regularizer: None  # Choose: l1, l2, l1
          optimizer: 'rmsprop'    # Choose: adam, sgd, rmsprop
          learning_rate: 0.00011572756412288465
          batch_size: 64
          epochs: 700 
        xgboost:
          eta: 0.0296919817778728
          n_estimators: 700    #700
          max_depth: 10
          reg_lambda: 0.11168295205556515
          reg_alpha: 0.8213385744671267
          colsample_bytree: 0.8622995700758153
        catboost:
          iterations: 1800 #1800
          depth: 10
          learning_rate: 0.05323725282124694
      LGM_TOT_P50:
        plotting:
          display_name: "SM"
          display_unit: r"$\log(M_{*}[M_{\odot}])$"
        dl:
          layers: [128, 96, 112, 80, 128]
          activation: 'relu'
          regularizer: 'l2'  # Choose: l1, l2, l1_l2, None
          optimizer: 'sgd'
          learning_rate: 0.003206298131994693
          batch_size: 32
          epochs: 1000
        wdnn:
          layers: [112, 96, 96]
          activation: 'elu'    # Choose: relu, elu, tanh
          regularizer: None  # Choose: l1, l2, l1_l2, None
          optimizer: 'rmsprop'    # Choose: adam, sgd, rms
          learning_rate: 0.00018911068696637922
          batch_size: 80
          epochs: 500 #500
        xgboost:
          eta: 0.022352866750231976
          n_estimators: 800    #800
          max_depth: 10
          reg_lambda: 0.6742971703149248
          reg_alpha: 0.8031056223432205
          colsample_bytree: 0.7952546069826849
        catboost:
          iterations: 2000 #2000
          depth: 11
          learning_rate: 0.04437318042938638

# Konfigurasi umum
scaler: 'RobustScaler'  # Choose: StandardScaler, MinMaxScaler, RobustScaler
validation_split: 0.1
k_fold: 5